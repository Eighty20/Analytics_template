---
title: "Formalise Model Pipeline on Spark Cluster"
output: html_notebook
---

```{r}
library(tidyverse)
library(sparklyr)
library(arrow)

config = spark_config()

config$`sparklyr.shell.driver-memory` <- "8G"
config$spark.memory.fraction <- 0.9

sc <- spark_connect(master = "local",config = config)
```

```{r}
train = readr::read_csv("../data/raw/train.csv")
test = readr::read_csv("../data/raw/test.csv")
```

```{r}
train_tbl = spark_read_csv(sc, name = "cover_type_train", path = "../data/raw/train.csv")
test_tbl = spark_read_csv(sc, name = "cover_type_test", path = "../data/raw/test.csv")
```

```{r}
pipeline = ml_pipeline(sc) %>% 
  ft_normalizer()
```

