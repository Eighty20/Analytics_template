---
title: "R Notebook"
output: html_notebook
---

```{r}
library(tidyverse)
library(sparklyr)
library(rsparkling)
library(h2o)
library(arrow)
library(recipes)
library(jsonlite)

config = spark_config()

config$`sparklyr.shell.driver-memory` <- "8G"
config$spark.memory.fraction <- 0.9

options(rsparkling.sparklingwater.version = "2.4.1")

sc <- spark_connect(master = "local",config = config)
```

## Goal of modelling

The purpose of the modelling exercise is to map some input or data to a desired objective.

In light ofthis we may build many different types of models, for example;

- Supervised models  
- Unsupervised models  
- Generative models  
- Probabilistic models  

To name a few. In this example we are trying to predict cover type given a set of actual observations so I will illustrate an example supervised learning approach.

```{r}
train_tbl = spark_read_csv(sc, name = "cover_type_train", path = "../data/raw/train.csv")
test_tbl = spark_read_csv(sc, name = "cover_type_test", path = "../data/raw/test.csv")
```

## Data pipeline

```{r}
source("../src/data_features/data_pipeline.r")
```

We can test the pipeline on the training set

```{r}
data_pipeline(train_tbl)
```


It is important to note that the pipeline is executed on the spark connection in this case because the input to the function is a spark frame.

If we call this function on the raw data however it will be executed using dplyr within R's memory.

This is useful though because our pipeline can be used to train the data in the spark connection and also be reused when preparing new raw data to be predicted on using the final model

## Train model

```{r}
train_h2o <- 
  train_tbl %>% 
  data_pipeline %>% 
  as_h2o_frame(sc = sc)

train_h2o["Cover_Type"] = as.factor(train_h2o["Cover_Type"])
```

```{r}
gbm_model <- 
  h2o.gbm(
    x = setdiff(names(train_h2o),"Cover_Type"),
    y = "Cover_Type",
    training_frame = train_h2o
  )
```

```{r}
gbm_model
```

```{r}
dl_model <- 
  h2o.deeplearning(
    x = setdiff(names(train_h2o),"Cover_Type"),
    y = "Cover_Type",
    training_frame = train_h2o
  )
```

```{r}
dl_model
```

We need to store the best model in a way we can deploy it without needed all the depencies required to actually train the model. We can do this by storing it as either a POJO or a MOJO object. See;  

<http://docs.h2o.ai/h2o/latest-stable/h2o-docs/productionizing.html>  

The POJO option stores it as a JAVA file. The MOJO option stores a zip file but this option is more optimized and modern.

```{r}
h2o.download_pojo(model = gbm_model,path = "../models/")
h2o.download_mojo(model = gbm_model,path = "../models/")
```

Let's test these objects

Load a sample of data we can test the model on

```{r}
test_sample <- 
  read_csv("../data/raw/train.csv") %>% 
  sample_n(size = 10,replace = F) 

# %>% 
  # data_pipeline()

test_sample_json <- toJSON(test_sample)

test_sample <- fromJSON(test_sample_json) %>% data_pipeline()
  
test_sample
```

Note that I have tested the pipeline using the data as a JSON input

See if we can make predictions

```{r}
h2o.mojo_predict_df(frame = test_sample,mojo_zip_path = "../models/GBM_model_R_1553005339156_4.zip")
```

## Model pipeline

Now that we have our POJO and MOJO objects we can create a simple application that uses them to make predictions

First we create a script describing the API that has a predict function

```{bash}
cat > ../src/models/predict.R <<EOF

# script name:
# predict.R

# set API title and description to show up in curl "http://127.0.0.1:8000/predict"/__swagger__/
#' @apiTitle Run predictions for the forest cover type based on various sample data
#' @apiDescription This API takes various data on features such as soil samples related to the forest canopy and predicts what cover type is present.
#' indicates cover type

# load model
# this path would have to be adapted if you would deploy this
data_pipeline_path = "/home/stefan/non_packrat/Analytics_template/src/data_features/data_pipeline.r"
recipe_path = "/home/stefan/non_packrat/Analytics_template/models/data_recipe_pipeline.rds"
source(data_pipeline_path)

# core function follows below:
# define parameters with type and description
# name endpoint
# return output as html/text
# specify 200 (okay) return

#' predict Cover Type using H2O gradient boosted model, expects the following variables as imput
#' @param Id
#' @param Elevation
#' @param Aspect
#' @param Slope
#' @param Horizontal_Distance_To_Hydrology
#' @param Vertical_Distance_To_Hydrology
#' @param Horizontal_Distance_To_Roadways
#' @param Hillshade_9am
#' @param Hillshade_Noon
#' @param Hillshade_3pm
#' @param Horizontal_Distance_To_Fire_Points
#' @param Wilderness_Area1
#' @param Wilderness_Area2
#' @param Wilderness_Area3
#' @param Wilderness_Area4
#' @param Soil_Type1
#' @param Soil_Type2
#' @param Soil_Type3
#' @param Soil_Type4
#' @param Soil_Type5
#' @param Soil_Type6
#' @param Soil_Type7
#' @param Soil_Type8
#' @param Soil_Type9
#' @param Soil_Type10
#' @param Soil_Type11
#' @param Soil_Type12
#' @param Soil_Type13
#' @param Soil_Type14
#' @param Soil_Type15
#' @param Soil_Type16
#' @param Soil_Type17
#' @param Soil_Type18
#' @param Soil_Type19
#' @param Soil_Type20
#' @param Soil_Type21
#' @param Soil_Type22
#' @param Soil_Type23
#' @param Soil_Type24
#' @param Soil_Type25
#' @param Soil_Type26
#' @param Soil_Type27
#' @param Soil_Type28
#' @param Soil_Type29
#' @param Soil_Type30
#' @param Soil_Type31
#' @param Soil_Type32
#' @param Soil_Type33
#' @param Soil_Type34
#' @param Soil_Type35
#' @param Soil_Type36
#' @param Soil_Type37
#' @param Soil_Type38
#' @param Soil_Type39
#' @param Soil_Type40
#' @param Cover_Type
#' @get /predict
calculate_prediction <- function(req) {
  
  input_json = fromJSON(txt = req\$postBody) %>% data_pipeline() %>% toJSON()
  
  pred_h2o = h2o.predict_json(model = '/home/stefan/non_packrat/Analytics_template/models/GBM_model_R_1553005339156_4.zip',json = input_json)
  
  req$body <- paste(pred_h2o %>% toJSON)

  req
  
}

EOF
```

```{r}
r <- plumb("/home/stefan/non_packrat/Analytics_template/src/models/predict.R")
```

```{r}
r
```


```{r}
r$run(host = "0.0.0.0", port=8000)
```


Now we create a script that will serve this function as a REST API

```{bash}
cat > ../src/models/serve_h2o_model.R <<EOF

#!/usr/bin/env R

library(tidyverse)
library(sparklyr)
library(rsparkling)
library(h2o)
library(arrow)
library(recipes)
library(jsonlite)
library(plumber)

r <- plumb("/home/stefan/non_packrat/Analytics_template/src/models/predict.R")
r\$run(host = "0.0.0.0", port=8000)

EOF
```

And make it executable

```{bash}
chmod +x ../src/models/predict.R
```

```{bash}
ls -l ../src/models/predict.R
```

Note the following;

- You need to run the API  

for example:  
`sudo Rscript /home/stefan/non_packrat/Analytics_template/src/models/serve_h2o_model.R`  

- In a normal production environment you will probably have to setup this part as a seperate light weight docker file  

- You will naturally have to open up a port to be able to test this API  

Now let's try to use the API

```{bash}
curl -H "Content-Type: application/json" -X POST -d '[{"Id":7588,"Elevation":3098,"Aspect":104,"Slope":10,"Horizontal_Distance_To_Hydrology":256,"Vertical_Distance_To_Hydrology":45,"Horizontal_Distance_To_Roadways":1935,"Hillshade_9am":237,"Hillshade_Noon":228,"Hillshade_3pm":121,"Horizontal_Distance_To_Fire_Points":1909,"Wilderness_Area1":0,"Wilderness_Area2":0,"Wilderness_Area3":1,"Wilderness_Area4":0,"Soil_Type1":0,"Soil_Type2":0,"Soil_Type3":0,"Soil_Type4":0,"Soil_Type5":0,"Soil_Type6":0,"Soil_Type7":0,"Soil_Type8":0,"Soil_Type9":0,"Soil_Type10":0,"Soil_Type11":0,"Soil_Type12":0,"Soil_Type13":1,"Soil_Type14":0,"Soil_Type15":0,"Soil_Type16":0,"Soil_Type17":0,"Soil_Type18":0,"Soil_Type19":0,"Soil_Type20":0,"Soil_Type21":0,"Soil_Type22":0,"Soil_Type23":0,"Soil_Type24":0,"Soil_Type25":0,"Soil_Type26":0,"Soil_Type27":0,"Soil_Type28":0,"Soil_Type29":0,"Soil_Type30":0,"Soil_Type31":0,"Soil_Type32":0,"Soil_Type33":0,"Soil_Type34":0,"Soil_Type35":0,"Soil_Type36":0,"Soil_Type37":0,"Soil_Type38":0,"Soil_Type39":0,"Soil_Type40":0,"Cover_Type":2}]' 35.242.157.248:8000/predict
```

`["[{"labelIndex":2,"label":"cover_type_3","classProbabilities":[0.0035,0.014,0.5687,0.1412,0.0086,0.2627,0.0013]}]"]`

